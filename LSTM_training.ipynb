{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa142da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#System Imports\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "\n",
    "#Data Processing Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "#Data Tokenization Imports\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "stopwords=set(stopwords.words('english'))\n",
    "maxLen = 150\n",
    "\n",
    "#ML Imports\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,Dense,SpatialDropout1D, Dropout, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d64d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Training Data\n",
    "pos_train = os.listdir(\"aclImdb/train/pos/\")\n",
    "neg_train = os.listdir(\"adaptready/aclImdb/train/neg/\")\n",
    "train_dict = {'positive':pos_train,'negative':neg_train}\n",
    "\n",
    "#Create a Train DataFrame\n",
    "df_train = pd.DataFrame(columns=['review_id','review_score','review_text', 'review_sentiment'])\n",
    "\n",
    "for key, val in train_dict.items():\n",
    "    for i in val:\n",
    "        try:\n",
    "            temp = i.replace('.txt','')\n",
    "            temp_1,temp_2 = temp.split('_')\n",
    "            f = open('aclImdb/train/'+key[:3]+'/'+i, 'r').read()\n",
    "            df_train.loc[len(df_train)] = [str(key[0])+\"_\"+temp_1,int(temp_2), f, key]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "#Load Testing Data\n",
    "pos_test = os.listdir(\"aclImdb/test/pos/\")\n",
    "neg_test = os.listdir(\"aclImdb/test/neg/\")\n",
    "test_dict = {'pos':pos_test,'neg':neg_test}\n",
    "\n",
    "#Create a Test DataFrame\n",
    "df_test = pd.DataFrame(columns=['review_id','review_score','review_text','review_sentiment'])\n",
    "\n",
    "for key, val in test_dict.items():\n",
    "    for i in val:\n",
    "        try:\n",
    "            temp = i.replace('.txt','')\n",
    "            temp_1,temp_2 = temp.split('_')\n",
    "            f = open('aclImdb/test/'+key[:3]+'/'+i, 'r').read()\n",
    "            df_test.loc[len(df_test)] = [str(key[0])+\"_\"+temp_1,int(temp_2),f, key]\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee50f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "\n",
    "def clean_further(string):\n",
    "    result = string.lower()\n",
    "    result = re.sub(r\"\\s{1,}\",\" \",result)\n",
    "    return result\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    df['review without stopwords'] = df['review_text'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "    df['clean_review']= df['review without stopwords'].apply(lambda cw : remove_tags(cw))\n",
    "    df['clean_review'] = df['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "    df['clean_review'] = df['clean_review'].apply(clean_further)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03be63aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91928\\AppData\\Local\\Temp\\ipykernel_14128\\488461178.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['clean_review'] = df['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
     ]
    }
   ],
   "source": [
    "#Clean the Dataset\n",
    "df_train = remove_stopwords(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e4cd006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_sentiment</th>\n",
       "      <th>review without stopwords</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p_0</td>\n",
       "      <td>9</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Bromwell High cartoon comedy. It ran time prog...</td>\n",
       "      <td>bromwell high cartoon comedy it ran time progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p_10000</td>\n",
       "      <td>8</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Homelessness (or Houselessness George Carlin s...</td>\n",
       "      <td>homelessness or houselessness george carlin st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p_10001</td>\n",
       "      <td>10</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Brilliant over-acting Lesley Ann Warren. Best ...</td>\n",
       "      <td>brilliant over acting lesley ann warren best d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p_10002</td>\n",
       "      <td>7</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>positive</td>\n",
       "      <td>This easily underrated film inn Brooks cannon....</td>\n",
       "      <td>this easily underrated film inn brooks cannon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p_10003</td>\n",
       "      <td>8</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>positive</td>\n",
       "      <td>This typical Mel Brooks film. It much less sla...</td>\n",
       "      <td>this typical mel brooks film it much less slap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id  review_score                                        review_text  \\\n",
       "0       p_0             9  Bromwell High is a cartoon comedy. It ran at t...   \n",
       "1   p_10000             8  Homelessness (or Houselessness as George Carli...   \n",
       "2   p_10001            10  Brilliant over-acting by Lesley Ann Warren. Be...   \n",
       "3   p_10002             7  This is easily the most underrated film inn th...   \n",
       "4   p_10003             8  This is not the typical Mel Brooks film. It wa...   \n",
       "\n",
       "  review_sentiment                           review without stopwords  \\\n",
       "0         positive  Bromwell High cartoon comedy. It ran time prog...   \n",
       "1         positive  Homelessness (or Houselessness George Carlin s...   \n",
       "2         positive  Brilliant over-acting Lesley Ann Warren. Best ...   \n",
       "3         positive  This easily underrated film inn Brooks cannon....   \n",
       "4         positive  This typical Mel Brooks film. It much less sla...   \n",
       "\n",
       "                                        clean_review  \n",
       "0  bromwell high cartoon comedy it ran time progr...  \n",
       "1  homelessness or houselessness george carlin st...  \n",
       "2  brilliant over acting lesley ann warren best d...  \n",
       "3  this easily underrated film inn brooks cannon ...  \n",
       "4  this typical mel brooks film it much less slap...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26570c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform Data into lists for train-test split \n",
    "reviews_list = []\n",
    "for i in range(len(df_train['clean_review'])):\n",
    "    reviews_list.append(df_train['clean_review'][i])\n",
    "    \n",
    "sentiment = df_train['review_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f89b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the Data into training and testing data\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiment)))\n",
    "\n",
    "X_train, X_test,Y_train, Y_test = train_test_split(reviews_list, y, test_size=0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc465c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a word tokenizer\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "words_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14e985df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the tokenizer\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with io.open('tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce3e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Word vectors embedding map\n",
    "def read_glove_vector(glove_vec):\n",
    "    with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            w_line = line.split()\n",
    "            curr_word = w_line[0]\n",
    "            word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map\n",
    "\n",
    "word_to_vec_map = read_glove_vector('glove.42B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13c5f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate an Embedding Layer\n",
    "vocab_len = len(words_to_index)\n",
    "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
    "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
    "\n",
    "for word, index in words_to_index.items():\n",
    "    break\n",
    "    embedding_vector = word_to_vec_map.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        emb_matrix[index-1, :] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, \n",
    "                            input_length=maxLen, weights = [emb_matrix], trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "befa885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Design the model\n",
    "def movie_rating(input_shape):\n",
    "    X_indices = Input(input_shape)\n",
    "    embeddings = embedding_layer(X_indices)\n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    X = Dropout(0.6)(X)\n",
    "    X = LSTM(128, return_sequences=True)(X)\n",
    "    X = Dropout(0.6)(X)\n",
    "    X = LSTM(128)(X)\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    model = Model(inputs=X_indices, outputs=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a4289cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 150)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     multiple                  21034800  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 150, 128)          219648    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 150, 128)          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 150, 128)          131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 150, 128)          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,517,745\n",
      "Trainable params: 482,945\n",
      "Non-trainable params: 21,034,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = movie_rating((maxLen,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a60cdcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "313/313 [==============================] - 265s 817ms/step - loss: 0.5833 - accuracy: 0.6843\n",
      "Epoch 2/15\n",
      "313/313 [==============================] - 273s 872ms/step - loss: 0.4153 - accuracy: 0.8199\n",
      "Epoch 3/15\n",
      "313/313 [==============================] - 1081s 3s/step - loss: 0.3756 - accuracy: 0.8381\n",
      "Epoch 4/15\n",
      "313/313 [==============================] - 259s 828ms/step - loss: 0.3521 - accuracy: 0.8490\n",
      "Epoch 5/15\n",
      "313/313 [==============================] - 1081s 3s/step - loss: 0.3399 - accuracy: 0.8537\n",
      "Epoch 6/15\n",
      "313/313 [==============================] - 258s 826ms/step - loss: 0.3309 - accuracy: 0.8599\n",
      "Epoch 7/15\n",
      "313/313 [==============================] - 5652s 18s/step - loss: 0.3210 - accuracy: 0.8644\n",
      "Epoch 8/15\n",
      "313/313 [==============================] - 261s 832ms/step - loss: 0.3104 - accuracy: 0.8703\n",
      "Epoch 9/15\n",
      "313/313 [==============================] - 259s 827ms/step - loss: 0.3056 - accuracy: 0.8706\n",
      "Epoch 10/15\n",
      "313/313 [==============================] - 3145s 10s/step - loss: 0.2947 - accuracy: 0.8767\n",
      "Epoch 11/15\n",
      "313/313 [==============================] - 261s 833ms/step - loss: 0.2880 - accuracy: 0.8808\n",
      "Epoch 12/15\n",
      "313/313 [==============================] - 265s 847ms/step - loss: 0.2813 - accuracy: 0.8842\n",
      "Epoch 13/15\n",
      "313/313 [==============================] - 281s 897ms/step - loss: 0.2764 - accuracy: 0.8852\n",
      "Epoch 14/15\n",
      "313/313 [==============================] - 1942s 6s/step - loss: 0.2651 - accuracy: 0.8919\n",
      "Epoch 15/15\n",
      "313/313 [==============================] - 263s 841ms/step - loss: 0.2572 - accuracy: 0.8973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x219f80fd3c0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')\n",
    "adam = Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_indices, Y_train, batch_size=64, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3dbedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f8e0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the evaluate the test dataset\n",
    "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
    "\n",
    "model.evaluate(X_test_indices, Y_test)\n",
    "preds = model.predict(X_test_indices)\n",
    "\n",
    "df_test = remove_stopwords(df_test)\n",
    "\n",
    "X_test_indices = tokenizer.texts_to_sequences(list(df_test['clean_review']))\n",
    "\n",
    "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aa9825d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the test dataset\n",
    "def add_score_predictions(data, reviews_list_idx):\n",
    "    maxLen = 150\n",
    "    data['sentiment score'] = 0\n",
    "\n",
    "    reviews_list_idx = pad_sequences(reviews_list_idx, maxlen=maxLen, padding='post')\n",
    "\n",
    "    review_preds = model.predict(reviews_list_idx)\n",
    "\n",
    "    data['sentiment score'] = review_preds\n",
    "\n",
    "    pred_sentiment = np.array(list(map(lambda x : 'positive' if x > 0.5 else 'negative',review_preds)))\n",
    "\n",
    "    data['predicted sentiment'] = 0\n",
    "\n",
    "    data['predicted sentiment'] = pred_sentiment\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f4568a89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 148s 187ms/step\n"
     ]
    }
   ],
   "source": [
    "test_df = add_score_predictions(data_test_without_stopwords,X_test_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
